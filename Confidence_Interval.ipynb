{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IndraniMandal/New-Revisions/blob/main/Confidence_Interval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YDlHnUeQP3r",
        "outputId": "d13ed6d1-f47d-48a5-9716-abbf33bbf17a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "###### Set Up #####\n",
        "# verify our folder with the data and module assets is installed\n",
        "# if it is installed make sure it is the latest\n",
        "!test -e ds-assets && cd ds-assets && git pull && cd ..\n",
        "# if it is not installed clone it \n",
        "!test ! -e ds-assets && git clone https://github.com/IndraniMandal/ds-assets.git\n",
        "# point to the folder with the assets\n",
        "home = \"ds-assets/assets/\" \n",
        "import sys\n",
        "sys.path.append(home)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ds-assets'...\n",
            "remote: Enumerating objects: 168, done.\u001b[K\n",
            "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 168 (delta 0), reused 2 (delta 0), pack-reused 164\u001b[K\n",
            "Receiving objects: 100% (168/168), 7.40 MiB | 23.53 MiB/s, done.\n",
            "Resolving deltas: 100% (60/60), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0B8hUcg-QP3a"
      },
      "source": [
        "# Classification Confidence Intervals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWk5RDxqQP3g"
      },
      "source": [
        "**Observation:** It does not matter how careful we are with our model evaluation techniques, there remains a fundamental uncertainty about the ability of our training data to effectively represent our (possibly infinite) data universe.\n",
        "\n",
        "This uncertainty reflects into our model evaluation. If our training data is a poor representation of the data universe then the models we construct using it will generalize poorly to the rest of the data universe. If our training data is a good representation of the data universe then we can expect that our model will generalize well.\n",
        "\n",
        "Here we will deal with this uncertainty using *confidence intervals*. First, let us define confidence intervals formally. Given a model accuracy, *acc*, then the confidence interval is defined as the probability *p that our model accuracy acc* lies between some lower bound *lb* and some upper bound *ub*,"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4xoF2wCQP3j"
      },
      "source": [
        "\\begin{equation}\n",
        "Pr(lb ≤ acc ≤ ub) = p\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MT8vYd7uQP3l"
      },
      "source": [
        "Paraphrasing this equation with *p = 95%*:\n",
        "\n",
        ">We are 95% percent sure that our model accuracy is not worse than *lb* and not better than *ub*.\n",
        "\n",
        "Ultimitely we are interested in the lower and upper bounds of the 95% confidence interval. We can use the following formula to compute the bounds:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKJtmlMqQP3m"
      },
      "source": [
        "\\begin{equation}\n",
        "ub = acc + 1.96 \\sqrt\\frac{acc(1-acc)}{n}\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfMrbP_VQP3n"
      },
      "source": [
        "\\begin{equation}\n",
        "lb = acc - 1.96 \\sqrt\\frac{acc(1-acc)}{n}\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwGgh8tzQP3p"
      },
      "source": [
        "Here, *n* is the number of observations in the testing dataset used to estimate *acc*. The constant 1.96 is called the *z-score* and expresses the fact that we are computing the 95% confidence interval.\n",
        "* 1.64 (90%)\n",
        "* 1.96 (95%)\n",
        "* 2.33 (98%)\n",
        "* 2.58 (99%)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prRAw5MPQP3q"
      },
      "source": [
        "# Classification Confidence Intervals in Python"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwyWlWVfQP30",
        "outputId": "2d610da5-4649-4cba-e53c-a8cd0ee1f70b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# cross-validation Iris\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "np.set_printoptions(formatter={'float_kind':\"{:3.2f}\".format})\n",
        "from sklearn import tree\n",
        "# grab cross validation code\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# get data\n",
        "url = 'https://raw.githubusercontent.com/IndraniMandal/ds-assets/main/assets/wdbc.csv' # the URL\n",
        "df = pd.read_csv(url)\n",
        "X  = df.drop(['id','Species'],axis=1)\n",
        "y = df['Species']\n",
        "\n",
        "# set up the model\n",
        "model = tree.DecisionTreeClassifier(criterion='entropy', max_depth=2)\n",
        "\n",
        "# do the 5-fold cross validation\n",
        "scores = cross_val_score(model, X, y, cv=5)\n",
        "print(\"Fold Accuracies: {}\".format(scores))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fold Accuracies: [0.93 0.97 0.90 0.87 1.00]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1BXzdznQP36"
      },
      "source": [
        "Let's do a simple example using the function classification_confint."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7Xp8xKnQP37"
      },
      "source": [
        "# compute 95% confidence intervals for classification and regression\n",
        "# problems\n",
        "\n",
        "def classification_confint(acc, n):\n",
        "    '''\n",
        "    Compute the 95% confidence interval for a classification problem.\n",
        "      acc -- classification accuracy\n",
        "      n   -- number of observations used to compute the accuracy\n",
        "    Returns a tuple (lb,ub)\n",
        "    '''\n",
        "    import math\n",
        "    interval = 1.96*math.sqrt(acc*(1-acc)/n)\n",
        "    lb = max(0, acc - interval)\n",
        "    ub = min(1.0, acc + interval)\n",
        "    return (lb,ub)\n",
        "\n",
        "def regression_confint(rs_score, n, k):\n",
        "    '''\n",
        "    Compute the 95% confidence interval for a regression problem.\n",
        "      rs_score -- R^2 score\n",
        "      n        -- number of observations used to compute the R^2 score\n",
        "      k        -- number of independent variables in dataset\n",
        "    Returns a tuple (lb,ub)\n",
        "    Reference:\n",
        "    https://books.google.com/books?id=gkalyqTMXNEC&pg=PA88#v=onepage&q&f=false\n",
        "    '''\n",
        "    import math\n",
        "    interval = 2*math.sqrt((4*rs_score*(1-rs_score)**2*(n-k-1)**2)/((n**2 - 1)*(n+3)))\n",
        "    lb = max(0, rs_score - interval)\n",
        "    ub = min(1.0, rs_score + interval)\n",
        "    return (lb,ub)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYBrfnaWQP3_",
        "outputId": "26f6c90e-5701-4494-ac1c-d4152c366549",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "observations = 100\n",
        "acc = .88\n",
        "lb,ub = classification_confint(acc,observations)\n",
        "print('Accuracy: {} ({:3.2f},{:3.2f})'.format(acc,lb, ub))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.88 (0.82,0.94)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMIUJ9VsQP4D"
      },
      "source": [
        "Now, let's do an actual example using the Wisconsin breast cancer dataset. We want to print out the testing accuracy together with it's 95% confidence interval."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhkUEQnMQP4E",
        "outputId": "ba93d149-9551-4bfc-9821-5bb364b5d2f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn import tree\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# read the data\n",
        "df = pd.read_csv(notes_home+\"assets/wdbc.csv\")\n",
        "\n",
        "# set up the feature matrix and target vector\n",
        "X  = df.drop(['ID','Diagnosis'],axis=1)\n",
        "y = df['Diagnosis']\n",
        "\n",
        "# split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=2)\n",
        "\n",
        "# set up the tree model object - limit the complexity to put us somewhere in the middle of the graph.\n",
        "model = tree.DecisionTreeClassifier(criterion='entropy', max_depth=4, random_state=1)\n",
        "\n",
        "# fit the model on the training set of data\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Test results: evaluate the model on the testing set of data\n",
        "y_test_model = model.predict(X_test)\n",
        "acc = accuracy_score(y_test, y_test_model)\n",
        "observations = X_test.shape[0]\n",
        "lb,up = classification_confint(acc, observations)\n",
        "print(\"Accuracy: {:3.2f} ({:3.2f},{:3.2f})\".format(acc,lb,ub))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.91 (0.86,0.94)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDtOgPxvQP4V"
      },
      "source": [
        "## Statistical Significance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxbnmBugQP4W"
      },
      "source": [
        "Besides giving us an idea of the uncertainty of our model the 95% confidence intervals also have something to say about the significance of scores of different models. That is, if the confidence intervals overlap then the difference in model performance of two different models on the same dataset is not statistically significant.\n",
        "\n",
        "Consider the following,"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSqQcLuzQP4X",
        "outputId": "01265382-311a-4033-a0ad-d0f74b3326d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#from assets.confint import classification_confint\n",
        "\n",
        "observations = 100\n",
        "\n",
        "# first classifier\n",
        "acc1 = .88\n",
        "lb1,ub1 = classification_confint(acc1,observations)\n",
        "print('Accuracy: {} ({:3.2f},{:3.2f})'.format(acc1,lb1, ub1))\n",
        "\n",
        "# second classifier\n",
        "acc2 = .92\n",
        "lb2,ub2 = classification_confint(acc2,observations)\n",
        "print('Accuracy: {} ({:3.2f},{:3.2f})'.format(acc2,lb2, ub2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.88 (0.82,0.94)\n",
            "Accuracy: 0.92 (0.87,0.97)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TF-T6gF6QP4a"
      },
      "source": [
        "Even though the second classifier has a better raw accuracy when we look at the confidence intervals of the two classifiers we see that they overlap. Here we see that the first classifier could potentially have an accuracy of .94 (even better than the raw accuracy of the second classifier). Furthermore, the confidence interval of the second classifier tells us that that classifier could potentially have an accuracy of .87 which is worse than the raw accuracy of the first classifier. For this reason we say that the difference in accuracy of two classifiers is not statistically significant if their confidence intervals overlap."
      ]
    }
  ]
}